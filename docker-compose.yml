# ============================================================================
# TERMIO â€” Docker Compose Configuration
# ============================================================================

version: "3.9"

services:
  # Rust HTTP server
  server:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8080:8080"
    environment:
      - TERMIO_SERVER_HOST=0.0.0.0
      - TERMIO_SERVER_PORT=8080
      - TERMIO_AI_SERVICE_URL=http://ai-service:8000
      - TERMIO_MEMORY_DATABASE_PATH=/data/termio.db
      - RUST_LOG=termio_server=info,tower_http=debug,audit=info
    volumes:
      - termio-data:/data
      - ./config:/app/config:ro
    depends_on:
      ai-service:
        condition: service_healthy
    networks:
      - termio-net
    restart: unless-stopped

  # Python AI inference service
  ai-service:
    build:
      context: ./ai_service
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - MODEL_PATH=/models/model.gguf
      - EMBEDDING_MODEL=all-MiniLM-L6-v2
      - NLU_MODEL_PATH=
      - VISION_MODEL=openai/clip-vit-base-patch32
    volumes:
      - termio-models:/models
    networks:
      - termio-net
    restart: unless-stopped

volumes:
  termio-data:
    driver: local
  termio-models:
    driver: local

networks:
  termio-net:
    driver: bridge
